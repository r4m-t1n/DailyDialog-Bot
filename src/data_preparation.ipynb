{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b469d9f-8a35-4266-ad53-42744bae2597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b67e3a2e-eae3-40e1-94e7-2326837ee441",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = r\"..\\data\"\n",
    "TRAIN_DIR = os.path.join(BASE_DIR, r\"train\\dialogues_train.txt\")\n",
    "VALID_DIR = os.path.join(BASE_DIR, r\"validation\\dialogues_validation.txt\")\n",
    "TEST_DIR = os.path.join(BASE_DIR, r\"test\\dialogues_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0d40ed6c-4a50-4088-9d63-6526d8740926",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-zA-Z0-9\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aade4da0-6f4a-4d4a-9c75-841a42ccca35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>You know that is tempting but is really not go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>What do you mean ? It will help us to relax .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>Do you really think so ? I don't . It will jus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>I guess you are right.But what shall we do ? I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>I suggest a walk over to the gym where we can ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Say , Jim , how about going for a few beers af...   \n",
       "1  Say , Jim , how about going for a few beers af...   \n",
       "2  Say , Jim , how about going for a few beers af...   \n",
       "3  Say , Jim , how about going for a few beers af...   \n",
       "4  Say , Jim , how about going for a few beers af...   \n",
       "\n",
       "                                            response  \n",
       "0  You know that is tempting but is really not go...  \n",
       "1      What do you mean ? It will help us to relax .  \n",
       "2  Do you really think so ? I don't . It will jus...  \n",
       "3  I guess you are right.But what shall we do ? I...  \n",
       "4  I suggest a walk over to the gym where we can ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_dialogue_pairs(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"UTF-8\") as f:\n",
    "        raw_lines = f.readlines()\n",
    "\n",
    "    dialogs = [line.strip().split(\"__eou__\") for line in raw_lines]\n",
    "    dialogs_cleaned = [[utt.strip() for utt in dialog if utt.strip()] for dialog in dialogs]\n",
    "\n",
    "    pairs = []\n",
    "    for dialog in dialogs_cleaned:\n",
    "        for i in range(len(dialog) - 1):\n",
    "            context = \" \".join(dialog[:i+1]).strip()\n",
    "            response = dialog[i+1].strip()\n",
    "            if context and response:\n",
    "                pairs.append({\"context\": context, \"response\": response})\n",
    "    return pairs\n",
    "\n",
    "train_pairs = load_dialogue_pairs(TRAIN_DIR)\n",
    "valid_pairs = load_dialogue_pairs(VALID_DIR)\n",
    "test_pairs = load_dialogue_pairs(TEST_DIR)\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame(train_pairs)\n",
    "df_valid = pd.DataFrame(valid_pairs)\n",
    "df_test = pd.DataFrame(test_pairs)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4fa0fd9a-a6b8-4f85-8dd7-207ec78a80cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [df_train, df_valid, df_test]:\n",
    "    df[\"context_clean\"] = df[\"context\"].apply(preprocess_text)\n",
    "    df[\"response_clean\"] = df[\"response\"].apply(preprocess_text)\n",
    "    df[\"context_tokens\"] = df[\"context_clean\"].apply(lambda x: x.split())\n",
    "    df[\"response_tokens\"] = df[\"response_clean\"].apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "887fa510-ebe6-444a-86b6-90db1224faf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>response</th>\n",
       "      <th>context_clean</th>\n",
       "      <th>response_clean</th>\n",
       "      <th>context_tokens</th>\n",
       "      <th>response_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>You know that is tempting but is really not go...</td>\n",
       "      <td>say jim how about going for a few beers after ...</td>\n",
       "      <td>you know that is tempting but is really not go...</td>\n",
       "      <td>[say, jim, how, about, going, for, a, few, bee...</td>\n",
       "      <td>[you, know, that, is, tempting, but, is, reall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>What do you mean ? It will help us to relax .</td>\n",
       "      <td>say jim how about going for a few beers after ...</td>\n",
       "      <td>what do you mean it will help us to relax</td>\n",
       "      <td>[say, jim, how, about, going, for, a, few, bee...</td>\n",
       "      <td>[what, do, you, mean, it, will, help, us, to, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>Do you really think so ? I don't . It will jus...</td>\n",
       "      <td>say jim how about going for a few beers after ...</td>\n",
       "      <td>do you really think so i dont it will just mak...</td>\n",
       "      <td>[say, jim, how, about, going, for, a, few, bee...</td>\n",
       "      <td>[do, you, really, think, so, i, dont, it, will...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>I guess you are right.But what shall we do ? I...</td>\n",
       "      <td>say jim how about going for a few beers after ...</td>\n",
       "      <td>i guess you are rightbut what shall we do i do...</td>\n",
       "      <td>[say, jim, how, about, going, for, a, few, bee...</td>\n",
       "      <td>[i, guess, you, are, rightbut, what, shall, we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Say , Jim , how about going for a few beers af...</td>\n",
       "      <td>I suggest a walk over to the gym where we can ...</td>\n",
       "      <td>say jim how about going for a few beers after ...</td>\n",
       "      <td>i suggest a walk over to the gym where we can ...</td>\n",
       "      <td>[say, jim, how, about, going, for, a, few, bee...</td>\n",
       "      <td>[i, suggest, a, walk, over, to, the, gym, wher...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             context  \\\n",
       "0  Say , Jim , how about going for a few beers af...   \n",
       "1  Say , Jim , how about going for a few beers af...   \n",
       "2  Say , Jim , how about going for a few beers af...   \n",
       "3  Say , Jim , how about going for a few beers af...   \n",
       "4  Say , Jim , how about going for a few beers af...   \n",
       "\n",
       "                                            response  \\\n",
       "0  You know that is tempting but is really not go...   \n",
       "1      What do you mean ? It will help us to relax .   \n",
       "2  Do you really think so ? I don't . It will jus...   \n",
       "3  I guess you are right.But what shall we do ? I...   \n",
       "4  I suggest a walk over to the gym where we can ...   \n",
       "\n",
       "                                       context_clean  \\\n",
       "0  say jim how about going for a few beers after ...   \n",
       "1  say jim how about going for a few beers after ...   \n",
       "2  say jim how about going for a few beers after ...   \n",
       "3  say jim how about going for a few beers after ...   \n",
       "4  say jim how about going for a few beers after ...   \n",
       "\n",
       "                                      response_clean  \\\n",
       "0  you know that is tempting but is really not go...   \n",
       "1          what do you mean it will help us to relax   \n",
       "2  do you really think so i dont it will just mak...   \n",
       "3  i guess you are rightbut what shall we do i do...   \n",
       "4  i suggest a walk over to the gym where we can ...   \n",
       "\n",
       "                                      context_tokens  \\\n",
       "0  [say, jim, how, about, going, for, a, few, bee...   \n",
       "1  [say, jim, how, about, going, for, a, few, bee...   \n",
       "2  [say, jim, how, about, going, for, a, few, bee...   \n",
       "3  [say, jim, how, about, going, for, a, few, bee...   \n",
       "4  [say, jim, how, about, going, for, a, few, bee...   \n",
       "\n",
       "                                     response_tokens  \n",
       "0  [you, know, that, is, tempting, but, is, reall...  \n",
       "1  [what, do, you, mean, it, will, help, us, to, ...  \n",
       "2  [do, you, really, think, so, i, dont, it, will...  \n",
       "3  [i, guess, you, are, rightbut, what, shall, we...  \n",
       "4  [i, suggest, a, walk, over, to, the, gym, wher...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d510b7d-2e59-4ab2-999f-bcbd1f236a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tokens = []\n",
    "for df in [df_train, df_valid, df_test]:\n",
    "    for tokens_list in df[\"context_tokens\"]:\n",
    "        all_tokens.extend(tokens_list)\n",
    "    for tokens_list in df[\"response_tokens\"]:\n",
    "        all_tokens.extend(tokens_list)\n",
    "\n",
    "word_counts = Counter(all_tokens)\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "SOS_IDX = 2\n",
    "EOS_IDX = 3\n",
    "\n",
    "vocab = {\n",
    "    word: i + 4 for i, (word, _) in enumerate(word_counts.most_common()) if word not in [\"<PAD>\", \"<UNK>\", \"<SOS>\", \"<EOS>\"]\n",
    "}\n",
    "vocab[\"<PAD>\"] = PAD_IDX\n",
    "vocab[\"<UNK>\"] = UNK_IDX\n",
    "vocab[\"<SOS>\"] = SOS_IDX\n",
    "vocab[\"<EOS>\"] = EOS_IDX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "992328bc-e82e-4fd9-9830-edf5495d85ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {idx: word for word, idx in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c201e435-b010-4f03-bef0-1c1fde8eb180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokens_to_indices(tokens, vocab):\n",
    "    return [vocab.get(token, vocab[\"<UNK>\"]) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4316213d-dd8b-48fc-b558-2ccf89abfd4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad(seq, max_len, pad_value=0):\n",
    "    if len(seq) > max_len:\n",
    "        seq = seq[:max_len]\n",
    "    elif len(seq) < max_len:\n",
    "        seq = seq + [pad_value] * (max_len - len(seq))\n",
    "    return seq\n",
    "\n",
    "max_len_context = 40\n",
    "max_len_response = 42\n",
    "\n",
    "for df in [df_train, df_valid, df_test]:\n",
    "    df[\"context_idx\"] = df[\"context_tokens\"].apply(\n",
    "        lambda x: tokens_to_indices(x, vocab)\n",
    "    )\n",
    "    df[\"response_idx\"] = df[\"response_tokens\"].apply(\n",
    "        lambda x: [vocab[\"<SOS>\"]] + tokens_to_indices(x, vocab) + [vocab[\"<EOS>\"]]\n",
    "    )\n",
    "    df[\"context_idx_padded\"] = df[\"context_idx\"].apply(\n",
    "        lambda x: pad(x, max_len_context, PAD_IDX)\n",
    "    )\n",
    "    df[\"response_idx_padded\"] = df[\"response_idx\"].apply(\n",
    "        lambda x: pad(x, max_len_response, PAD_IDX)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b5aa625-0143-46c5-b1a2-95ca356f62e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2SeqDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.contexts = df[\"context_idx_padded\"].tolist()\n",
    "        self.responses = df[\"response_idx_padded\"].tolist()\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.contexts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        context = torch.tensor(self.contexts[idx], dtype=torch.long)\n",
    "        response = torch.tensor(self.responses[idx], dtype=torch.long)\n",
    "        return context, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7feb5c4-2849-446d-ae80-6d40378e7fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataset = Seq2SeqDataset(df_train)\n",
    "valid_dataset = Seq2SeqDataset(df_valid)\n",
    "test_dataset = Seq2SeqDataset(df_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9a10f21f-bc4f-4bf2-a2d2-f905ca7d1e5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(76053,\n",
       " (tensor([ 162,  885,   29,   33,   70,   15,    8,  186, 3197,  177,  289,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0]),\n",
       "  tensor([   2,    4,   44,   16,   10, 4335,   31,   10,   56,   43,   41,   15,\n",
       "            71, 1764,    3,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "             0,    0,    0,    0,    0,    0])))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1e9fb4e5-92bf-40f8-a062-e810287f8340",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        _, (hidden, cell) = self.lstm(embedded)\n",
    "        return hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56ed637d-5956-45d7-be13-5424e07a36c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_layers=1):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embed_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(1)\n",
    "        embedded = self.embedding(x)\n",
    "        outputs, (hidden, cell) = self.lstm(embedded, (hidden, cell))\n",
    "        predictions = self.fc(outputs.squeeze(1))\n",
    "        return predictions, hidden, cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b22f1e3-79aa-4014-8a1f-5ad441596b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super(Seq2Seq, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, source, target, teacher_forcing_ratio=0.5):\n",
    "        encoder_hidden, encoder_cell = self.encoder(source)\n",
    "\n",
    "        target_len = target.shape[1]\n",
    "        batch_size = target.shape[0]\n",
    "        vocab_size = self.decoder.fc.out_features\n",
    "\n",
    "        outputs = torch.zeros(target_len, batch_size, vocab_size).to(self.device)\n",
    "\n",
    "        decoder_input = target[:, 0]\n",
    "\n",
    "        hidden = encoder_hidden\n",
    "        cell = encoder_cell\n",
    "\n",
    "        for t in range(1, target_len):\n",
    "            prediction, hidden, cell = self.decoder(decoder_input, hidden, cell)\n",
    "            outputs[t] = prediction\n",
    "            teacher_force = torch.rand(1).item() < teacher_forcing_ratio\n",
    "            top1 = prediction.argmax(1)\n",
    "            decoder_input = target[:, t] if teacher_force else top1\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f15c35c8-ebb2-4ad0-8f28-4af9c66bccff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "122e69f4-3b75-427b-858b-5dc59f494a19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1be5a001-86f4-4ba1-a75a-c0e7772a9d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEN_VOCAB = len(vocab)\n",
    "EMB_DIM = 128\n",
    "EMB_DIM = 128\n",
    "HID_DIM = 256\n",
    "N_LAYERS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af7ad2e4-82f9-4dd2-97e9-bf07e62457d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(LEN_VOCAB, EMB_DIM, HID_DIM, N_LAYERS).to(device)\n",
    "decoder = Decoder(LEN_VOCAB, EMB_DIM, HID_DIM, N_LAYERS).to(device)\n",
    "model = Seq2Seq(encoder, decoder, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3cbc25f0-e389-4ccf-9149-adc05b68fbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a300afbb-23b4-4254-9c5f-204d6b87b39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2c0820b8-363b-40b7-9398-5a60fce2200e",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 10\n",
    "CLIP = 1\n",
    "\n",
    "best_valid_loss = float('inf')\n",
    "MODEL_SAVE_PATH = 'dd_chatbot_model.pt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fbe70ce3-57a9-4713-8bfc-62208ba326b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip):\n",
    "    model.train()\n",
    "\n",
    "    epoch_loss = 0\n",
    "    \n",
    "    for i, (src, trg) in enumerate(iterator):\n",
    "\n",
    "        src = src.to(device)\n",
    "        trg = trg.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, trg, teacher_forcing_ratio=0.5)\n",
    "\n",
    "        output_dim = output.shape[-1]\n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "        loss = criterion(output, trg)\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3e9146e4-3397-4e14-80a7-9ee198779842",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion):\n",
    "    model.eval()\n",
    "\n",
    "    epoch_loss = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (src, trg) in enumerate(iterator):\n",
    "            src = src.to(device)\n",
    "            trg = trg.to(device)\n",
    "\n",
    "            output = model(src, trg, teacher_forcing_ratio=0) \n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            output = output[1:].view(-1, output_dim)\n",
    "            trg = trg[:, 1:].reshape(-1)\n",
    "\n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "167b7de7-49ab-4758-9685-f9466a5256c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Time: 7m 56s\n",
      "\tTrain Loss: 6.302\n",
      "\tVal Loss: 6.247\n",
      "Model is saved with Val Loss: 6.247\n",
      "Epoch: 02 | Time: 9m 15s\n",
      "\tTrain Loss: 6.231\n",
      "\tVal Loss: 6.258\n",
      "Epoch: 03 | Time: 8m 57s\n",
      "\tTrain Loss: 6.227\n",
      "\tVal Loss: 6.265\n",
      "Epoch: 04 | Time: 8m 33s\n",
      "\tTrain Loss: 6.223\n",
      "\tVal Loss: 6.272\n",
      "Epoch: 05 | Time: 7m 44s\n",
      "\tTrain Loss: 6.220\n",
      "\tVal Loss: 6.277\n",
      "Epoch: 06 | Time: 7m 45s\n",
      "\tTrain Loss: 6.219\n",
      "\tVal Loss: 6.283\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(N_EPOCHS):\n\u001b[0;32m      2\u001b[0m     start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m----> 4\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCLIP\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m     valid_loss \u001b[38;5;241m=\u001b[39m evaluate(model, valid_loader, criterion)\n\u001b[0;32m      7\u001b[0m     end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "Cell \u001b[1;32mIn[24], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion, clip)\u001b[0m\n\u001b[0;32m      9\u001b[0m trg \u001b[38;5;241m=\u001b[39m trg\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 12\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_forcing_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     15\u001b[0m output \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output_dim)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[1;34m(self, source, target, teacher_forcing_ratio)\u001b[0m\n\u001b[0;32m     12\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m target\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     13\u001b[0m vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39mout_features\n\u001b[1;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     17\u001b[0m decoder_input \u001b[38;5;241m=\u001b[39m target[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     19\u001b[0m hidden \u001b[38;5;241m=\u001b[39m encoder_hidden\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(N_EPOCHS):\n",
    "    start_time = time.time()\n",
    "\n",
    "    train_loss = train(model, train_loader, optimizer, criterion, CLIP)\n",
    "    valid_loss = evaluate(model, valid_loader, criterion)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f}')\n",
    "    print(f'\\tVal Loss: {valid_loss:.3f}')\n",
    "\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        print(f\"Model is saved with Val Loss: {valid_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5995a8e-f2c8-436a-94ad-37ff436c5f34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
